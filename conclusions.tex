\section{Conclusions}\label{sec:conclusions}

The software metrics area is quite mature in SE. Their formal properties \cite{fenton2014software} and some common pitfalls, e.g., \cite{fenton1992software}, are well understood. However, when dealing with experimental data, it seems that we have overlooked, at least partially, the complexities of measurement. There are several reasons for that: (1) in many cases, the metrics and measuring instruments should be specifically designed for an experiment, (2) the entities of interest in SE are often theoretical constructs, so objective measurement instruments cannot, by definition, be ever available, (3) we probably trust in excess in the power of statistics, etc.

Our study shows that while the absolute values of quality and productivity metrics may vary significantly depending on the test suite used, the relative comparison between treatments (e.g., TDD vs. test-last) tends to remain stable across test suites. This suggests that test suites can be used as measurement instruments in TDD experiments, but only under the condition that they are properly aligned with the task specification. Their validity is therefore conditional, not universal. Moreover, we have confirmed in this research that different test suites (often used as measuring instruments) give different measures on the same program. Such differences are so radical that they reverse the effects of the factors in the statistical analyses. We have restricted our inquiry to the response variable \textit{external quality}, frequently used in TDD experiments. However, we believe that our findings can be extrapolated to other response variables, research areas and even other research methods, e.g., case studies.

Experimentation is not mature enough to introduce standard measures and measurement instruments. Of course, benchmarks can be adopted. However, the mere adoption of a benchmark does not solve the problems described in this paper because nothing guarantees that such a benchmark provides the \textit{right} measures. Even so, some actions should be taken to avoid the harmful effects of metrics and measuring instruments in SE experimental research. In our opinion, three measures can be beneficial for the experimental community:

\begin{itemize}

\item Researchers should disclose not only the measurement results, i.e., the refined data which proceeds to analysis but also the \textbf{raw data} (e.g., subjects' code) and the \textbf{measurement procedure and instruments}. This enables later critical examination and the conduction of a wide range of replications, in particular, re-analysis \cite{mittelstaedt1984econometric,IJzendoorn1994}, where the raw data is independently re-processed before analysis. 

\item The properties of the measures and measuring instruments should be considered before actual measurement takes place. In many cases, measurement standards, e.g., programs satisfying subsets of requirements, can be easily created well before the experiment is conducted, so that formal analysis and empirical studies are possible.

\item When standards are not available, experimenters could use different measures and instruments to avoid threats to construct validity. Coherent results obtained with different instruments would increase the confidence in the experiment results. Just to cite an example, in Experiment\_PT and Experiment\_EC, the \textit{Treatment} (ITLD vs. TDD) \textbf{was largely unaffected} by TestSuite\_AH and TestSuite\_EP. This fact provides us some relief. If the treatments were unaffected, the meta-analyses and other secondary studies based on these data would produce correct results.

\end{itemize}

One of the most important testing challenges is the lack of standards for comparing studies. The solution for this challenge is beyond the scope of this article, as it depends on the entire SE community. Measurement using test cases should be approached by choosing the best method to generate test suites, thereby creating a benchmark that can be reused across studies.

As limitations of our evaluation, we can summarize the following aspects. There exists the possibility of significant measurement variability due to differences in how the test suites are used by measurers, which can lead to contradictory results. Additionally, the experiment's reliance on specific test suite types (TestSuite\_AH and TestSuite\_EP) may limit the generalizability of the findings to other test suite construction methodologies. The context in which data was collected varied, potentially affecting the consistency of results. Finally, despite efforts to mitigate threats to external validity, such as using professional software developers and widely recognized experimental problems, these measures cannot eliminate the possibility of contextual factors influencing the outcomes.

Finally, in this research, we have only addressed the influence of the measuring instruments in the measurement results. However, the measurement process, as indicated in Section~\ref{sec:comparison}, has several components. They all (in particular, the measurer and the manipulations before applying the measuring instrument) can influence the measurement result too. The assessment of the impact of those elements will be future research.